# **************
# ** TEMPLATE **
# **************
#
# Common configurations between all FairGBM / LightGBM models.
#
verbosity = 0   # only warnings or errors

task = train
# eval metrics, support multi metric, delimited by ',' , support following metrics
# metric = binary_logloss,auc
# metric_freq = 5
# true if need output metric for training data, alias: tranining_metric, train_metric
# is_training_metric = true
# number of bins for feature bucket, 255 is a recommend setting, it can save memories, and also has good accuracy.
max_bin = 255
# training data
# if existing weight file, should name to "binary.train.weight"
# alias: train_data, train
# data = /home/andre.cruz/Documents/fair-boosting/data/Adult-2021/ACSIncome.train.header.csv
has_header = True
label_column = name:PINCP
# ignore_column = name:index          # columns to ignore (index column) -- # NOTE! Also ignore sensitive attribute?
# categorical_feature = # does not count label, column values should be consecutive ints

# validation data, support multi validation data, separated by ','
# if existing weight file, should name to "binary.test.weight"
# alias: valid, test, test_data,
valid_data = /mnt/home/andre.cruz/fair-boosting/data/Adult-2021/ACSIncome.validation.header.csv

num_threads = 1
random_state = 3407

# Categorical features
categorical_feature = name:COW,MAR,OCCP,POBP,RELP,RAC1P

# **NOTE** remaining hyperparameters will be randomly sampled and added to this file
data = /mnt/home/andre.cruz/fair-boosting/data/Adult-2021/ACSIncome.train.header.csv
ignore_column = name:index
boosting_type = goss
enable_bundle = False
n_estimators = 782
num_leaves = 25
min_child_samples = 105
max_depth = 4
learning_rate = 0.023863271847004226
reg_alpha = 0.0441448487067432
reg_lambda = 0.008880357660136735
output_dir = /mnt/home/andre.cruz/fair-boosting/experiments/Adult-2021/results/randomly-generated-configs/LightGBM/053
output_model = /mnt/home/andre.cruz/fair-boosting/experiments/Adult-2021/results/randomly-generated-configs/LightGBM/053/model.txt
